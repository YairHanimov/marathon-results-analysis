{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP - Dynamic - Selenium\n",
    "## IES - Python - Project\n",
    "### Marathon Results Analysis\n",
    "#### David Koubek, Jiri Zelenka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # for robots check\n",
    "from bs4 import BeautifulSoup # prettify HTML\n",
    "from selenium import webdriver # scraping JS dynamic elements\n",
    "from time import sleep # for sleeping (slowing down) inside a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robots.txt\n",
    "\n",
    "Are we allowed to scrape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get('https://www.runczech.com/robots.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response 200 means the request was fulfilled. Let's look visually at the actual robots.txt file what is allowed and what's not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n",
      "# robots.txt\n",
      "#\n",
      "\n",
      "# exclude these directories\n",
      "User-agent: *\n",
      "Disallow: /srv/\n",
      "Disallow: /cgi/\n",
      "Allow: /srv/www/qf/*/ramjet/eventList\n",
      "Allow: /srv/www/qf/*/ramjet/eventVoucherList\n",
      "Allow: /srv/www/qf/*/ramjet/contactPage\n",
      "Allow: /srv/www/qf/*/ramjet/raceDetail\n",
      "Allow: /srv/www/qf/*/ramjet/leagueDetail\n",
      "Allow: /srv/www/qf/*/ramjet/results/list\n",
      "Allow: /srv/www/qf/*/ramjet/results/league\n",
      "Allow: /srv/www/qf/*/ramjet/results/league/detail\n",
      "Allow: /srv/www/qf/*/ramjet/resultsEventDetail\n",
      "Allow: /srv/www/qf/*/ramjet/resultsSubEventUserDetail\n",
      "Allow: /srv/www/qf/*/ramjet/resultsSubEventGroupDetail\n",
      "Allow: /srv/www/qf/*/ramjet/event/runnerList\n",
      "\n",
      "Sitemap: https://www.runczech.com/sitemap-cs.xml\n",
      "Sitemap: https://www.runczech.com/sitemap-en.xml\n",
      "Sitemap: https://www.runczech.com/sitemap-de.xml\n",
      "Sitemap: https://www.runczech.com/sitemap-it.xml\n",
      "Sitemap: https://www.runczech.com/sitemap-fr.xml\n",
      "Sitemap: https://www.runczech.com/sitemap-es.xml\n",
      "Sitemap: https://www.runczech.com/sitemap-pl.xml\n",
      "Sitemap: https://www.runczech.com/sitemap-zh.xml\n",
      "Sitemap: https://www.runczech.com/sitemap-ru.xml\n",
      "Sitemap: https://www.runczech.com/sitemap-hu.xml\n",
      "Sitemap: https://www.runczech.com/sitemap-ja.xml\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(requests.get('https://www.runczech.com/robots.txt').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"resultsEventDetail\" which we desire to scrape is allowed which is good, we can proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping JavaScript dynamic website\n",
    " - https://www.google.com/search?q=python+scrape+website+that+has+script+inside+html&oq=python+scrape+website+that+has+script+inside+html&aqs=chrome..69i57.14882j0j7&sourceid=chrome&ie=UTF-8\n",
    "     - https://stackoverflow.com/questions/26680590/how-to-scrape-imbeded-script-on-webpage-in-python\n",
    "     - https://stanford.edu/~mgorkove/cgi-bin/rpython_tutorials/Scraping_a_Webpage_Rendered_by_Javascript_Using_Python.php\n",
    "     - https://www.youtube.com/watch?v=FSH77vnOGqU\n",
    "     - https://www.youtube.com/watch?v=vsmxMLmroyQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First make sure chromedriver is correctly in the environment (download from https://sites.google.com/a/chromium.org/chromedriver/ ), otherwise the webdriver scraping outputs an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all marathon links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The middlepage table of our webpage is not simply a static HTML code, it gets loaded in the browser only after we load the page, dynamically via JavaScript. So we have to use dynamic scraping methods, e.g. Selenium. After we've scraped the dynamic code, we need to scrape the \"a href\" tag of class \"indexList_link\" which contains URL links to the desired marathon events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to slow down the scraping inside get_soup function so the url gets fully loaded in the browser (JS table takes about 1-2s to pull data from servers) before it's scraped, otherwise the soup object will contain only the static parts of the website and not the dynamic ones which we care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapes dynamic webpage content using Selenium browser, returns a prettified soup code of the page\n",
    "def get_soup(url):\n",
    "    # Working with chrome, first open window\n",
    "    browser = webdriver.Chrome()\n",
    "    # Then navigate browser to desired url and get the source code\n",
    "    browser.get(url) # navigate to the page\n",
    "\n",
    "    # Wait 1-2s (1s might just be enough but better be safe closer to 2s)\n",
    "    sleep(2) # time in seconds, can also take a float value\n",
    "    \n",
    "    # Take all the inner code of the displayed webpage\n",
    "    innerHTML = browser.execute_script(\"return document.body.innerHTML\") #returns the inner HTML as a string\n",
    "    \n",
    "    # Clean with BeautifulSoup:\n",
    "    soup = BeautifulSoup(innerHTML,'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a given RunCzech Results URL, returns a list of events' URLs (marathons)\n",
    "def get_all_links(url):\n",
    "    soup = get_soup(url) # call get_soup function on the desired url and get back the soup from bs (of the dynamic HTML with JS elements loaded)\n",
    "    a_elements = soup.find_all('a',{'class':'indexList_link'}) # class \"indexList_link\" contains the href link we desire\n",
    "    urls_events = ['https://www.runczech.com' + a['href'] for a in a_elements] # list comprehension/function for links, join runczech url with the href ending of the events\n",
    "    return urls_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of Results webpage which contains links to marathons\n",
    "url_results = \"https://www.runczech.com/srv/www/qf/en/ramjet/results/list?&page=1&per_page=15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_marathons = get_all_links(url_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.runczech.com/srv/www/qf/en/ramjet/resultsEventDetail?eventId=22175',\n",
       " 'https://www.runczech.com/srv/www/qf/en/ramjet/resultsEventDetail?eventId=22166',\n",
       " 'https://www.runczech.com/srv/www/qf/en/ramjet/resultsEventDetail?eventId=22163',\n",
       " 'https://www.runczech.com/srv/www/qf/en/ramjet/resultsEventDetail?eventId=22114',\n",
       " 'https://www.runczech.com/srv/www/qf/en/ramjet/resultsEventDetail?eventId=21460',\n",
       " 'https://www.runczech.com/srv/www/qf/en/ramjet/resultsEventDetail?eventId=21453',\n",
       " 'https://www.runczech.com/srv/www/qf/en/ramjet/resultsEventDetail?eventId=21448',\n",
       " 'https://www.runczech.com/srv/www/qf/en/ramjet/resultsEventDetail?eventId=21636',\n",
       " 'https://www.runczech.com/srv/www/qf/en/ramjet/resultsEventDetail?eventId=21443',\n",
       " 'https://www.runczech.com/srv/www/qf/en/ramjet/resultsEventDetail?eventId=21438',\n",
       " 'https://www.runczech.com/srv/www/qf/en/ramjet/resultsEventDetail?eventId=21429',\n",
       " 'https://www.runczech.com/srv/www/qf/en/ramjet/resultsEventDetail?eventId=21426',\n",
       " 'https://www.runczech.com/srv/www/qf/en/ramjet/resultsEventDetail?eventId=20655',\n",
       " 'https://www.runczech.com/srv/www/qf/en/ramjet/resultsEventDetail?eventId=20648',\n",
       " 'https://www.runczech.com/srv/www/qf/en/ramjet/resultsEventDetail?eventId=20643']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_marathons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data table from marathon events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape a single table\n",
    "\n",
    "Coded for one link/table for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.runczech.com/srv/www/qf/en/ramjet/resultsEventDetail?eventId=22163'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_marathon_2019 = urls_marathons[2]\n",
    "url_marathon_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tr>\n",
      "<th class=\"hidden767\">Avatar</th>\n",
      "<th>Name</th>\n",
      "<th>Avg. chip<br/>time</th>\n",
      "<th>Members<br/>- in group</th>\n",
      "<th class=\"hidden767\">Members<br/>- participants</th>\n",
      "<th class=\"hidden767\">Group type</th>\n",
      "</tr>\n"
     ]
    }
   ],
   "source": [
    "# DELETE LATER, for playing around with simple one find cases\n",
    "def get_names(url):\n",
    "    soup = get_soup(url)\n",
    "\n",
    "    tr = soup.find('tr') # \"tr\" table-row element tag\n",
    "    \n",
    "    el = tr.find('th',{'class':'hidden767'}).find_next('th').contents[0]\n",
    "    \n",
    "    return tr\n",
    "#     return el\n",
    "\n",
    "names = get_names(url_marathon_2019)\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names(url):\n",
    "    soup = get_soup(url)\n",
    "\n",
    "    trs = soup.find_all('tr') # \"tr\" table-row element tag\n",
    "    \n",
    "    tds = [tr.find('td',{'class':'hidden980'}) for tr in trs] # hidden980 is class of first column\n",
    "    tds = [x for x in tds if x != None] # filter out the None elements in tds (where tds weren't present in tr tags),\n",
    "    # could also use filter(None, tds) which though gets rid of 0s as well which is more dangerous in certain situations\n",
    "    tds_sibsibling = [td.find_next('td').find_next('td') for td in tds] # finds next sibling of tag 'td'\n",
    "    contents = [td_sibling.contents[0] for td_sibling in tds_sibsibling] # returns just the text inside tags\n",
    "    \n",
    "    return contents # names are next to sibling of hidden980 class element/column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get \"Official time\" column\n",
    "def get_times(url):\n",
    "    soup = get_soup(url)\n",
    "\n",
    "    trs = soup.find_all('tr') # \"tr\" table-row element tag\n",
    "    \n",
    "    tds = [tr.find('td',{'class':'hidden767'}) for tr in trs] # hidden980 is class of first column\n",
    "    tds = [x for x in tds if x != None] # filter out the None elements in tds (where tds weren't present in tr tags),\n",
    "    # could also use filter(None, tds) which though gets rid of 0s as well which is more dangerous in certain situations\n",
    "    tds_sibling = [td.find_previous('td') for td in tds] # finds previous sibling of tag 'td', in this case the \"Official time\"\n",
    "    contents = [td_sibling.contents[0] for td_sibling in tds_sibling] # returns just the text inside tags\n",
    "    \n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Benard KIMELI',\n",
       " 'Felix KIBITOK',\n",
       " 'Stephen KIPROP',\n",
       " 'Geoffrey Kimutai KOECH',\n",
       " 'Henry RONO',\n",
       " 'Moses KIBET',\n",
       " 'Moses Kipngetich KEMEI',\n",
       " 'Yohanes GHEBREGERGIS',\n",
       " 'Ishmael Chelanga KALALE',\n",
       " 'Philimon Kipkorir MARITIM',\n",
       " 'Abel KIPCHUMBA',\n",
       " 'Jiří HOMOLÁČ',\n",
       " 'Felix BOUR',\n",
       " 'Igor OLEFIRENKO',\n",
       " 'Caroline Chepkoech KIPKIRUI']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_2019 = get_names(url_marathon_2019)\n",
    "names_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0:59:07',\n",
       " '0:59:08',\n",
       " '0:59:20',\n",
       " '1:00:30',\n",
       " '1:00:37',\n",
       " '1:00:59',\n",
       " '1:01:19',\n",
       " '1:01:44',\n",
       " '1:01:45',\n",
       " '1:02:04',\n",
       " '1:02:07',\n",
       " '1:04:03',\n",
       " '1:04:18',\n",
       " '1:04:23',\n",
       " '1:05:44']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_2019 = get_times(url_marathon_2019)\n",
    "times_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
